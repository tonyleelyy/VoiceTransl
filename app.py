import sys, os

# os.chdir(sys._MEIPASS)
import shutil
from PyQt5 import QtGui, QtCore
from PyQt5.QtCore import Qt, QThread, QObject, pyqtSignal, QTimer, QDateTime, QSize
from PyQt5.QtWidgets import QApplication, QVBoxLayout, QFileDialog, QFrame
from qfluentwidgets import PushButton as QPushButton, TextEdit as QTextEdit, LineEdit as QLineEdit, ComboBox as QComboBox, Slider as QSlider, FluentWindow as QMainWindow, PlainTextEdit as QPlainTextEdit, SplashScreen
from qfluentwidgets import FluentIcon, NavigationItemPosition, SubtitleLabel, TitleLabel, BodyLabel

import re
import json
import requests
import subprocess
from time import sleep
from yt_dlp import YoutubeDL
from bilibili_dl.bilibili_dl.Video import Video
from bilibili_dl.bilibili_dl.downloader import download
from bilibili_dl.bilibili_dl.utils import send_request
from bilibili_dl.bilibili_dl.constants import URL_VIDEO_INFO

from prompt2srt import make_srt, make_lrc
from srt2prompt import make_prompt, merge_srt_files
from GalTransl.__main__ import worker

ONLINE_TRANSLATOR_MAPPING = {
    'moonshot': 'https://api.moonshot.cn',
    'glm': 'https://open.bigmodel.cn/api/paas',
    'deepseek': 'https://api.deepseek.com',
    'minimax': 'https://api.minimax.chat',
    'doubao': 'https://ark.cn-beijing.volces.com/api',
    'aliyun': 'https://dashscope.aliyuncs.com/compatible-mode',
    'gemini': 'https://generativelanguage.googleapis.com',
    'ollama': 'http://localhost:11434',
    'llamacpp': 'http://localhost:8989',
}

TRANSLATOR_SUPPORTED = [
    'ä¸è¿›è¡Œç¿»è¯‘',
    "gpt-custom",
    "sakura-009",
    "sakura-010",
    "galtransl"
] + list(ONLINE_TRANSLATOR_MAPPING.keys())

# redirect sys.stdout and sys.stderr to one log file
LOG_PATH = 'log.txt'
sys.stdout = open(LOG_PATH, 'w', encoding='utf-8')
sys.stderr = sys.stdout

class Widget(QFrame):

    def __init__(self, text: str, parent=None):
        super().__init__(parent=parent)
        # Set the scroll area as the parent of the widget
        self.vBoxLayout = QVBoxLayout(self)

        # Must set a globally unique object name for the sub-interface
        self.setObjectName(text.replace(' ', '-'))

class MainWindow(QMainWindow):
    status = pyqtSignal(str)

    def __init__(self):
        super().__init__()
        self.thread = None
        self.worker = None
        self.setWindowTitle("VoiceTransl")
        self.setWindowIcon(QtGui.QIcon('icon.png'))
        self.status.connect(lambda x: self.setWindowTitle(f"VoiceTransl - {x}"))
        self.resize(800, 600)
        self.splashScreen = SplashScreen(self.windowIcon(), self)
        self.splashScreen.setIconSize(QSize(102, 102))
        self.show()
        self.initUI()
        self.setup_timer()
        self.splashScreen.finish()
        
    def initUI(self):
        self.initAboutTab()
        self.initInputOutputTab()
        self.initLogTab()
        self.initSettingsTab()
        self.initAdvancedSettingTab()
        self.initDictTab()
        self.initClipTab()
        self.initSynthTab()
        self.initSummarizeTab()

        # load config
        if os.path.exists('config.txt'):
            with open('config.txt', 'r', encoding='utf-8') as f:
                lines = f.readlines()
                whisper_file = lines[0].strip()
                translator = lines[1].strip()
                language = lines[2].strip()
                gpt_token = lines[3].strip()
                gpt_address = lines[4].strip()
                gpt_model = lines[5].strip()
                sakura_file = lines[6].strip()
                sakura_mode = int(lines[7].strip())
                proxy_address = lines[8].strip()
                summary_address = lines[9].strip()
                summary_model = lines[10].strip()
                summary_token = lines[11].strip()
                uvr_file = lines[12].strip()
                output_format = lines[13].strip()

                if self.whisper_file: self.whisper_file.setCurrentText(whisper_file)
                self.translator_group.setCurrentText(translator)
                self.input_lang.setCurrentText(language)
                self.gpt_token.setText(gpt_token)
                self.gpt_address.setText(gpt_address)
                self.gpt_model.setText(gpt_model)
                if self.sakura_file: self.sakura_file.setCurrentText(sakura_file)
                self.sakura_mode.setValue(sakura_mode)
                self.proxy_address.setText(proxy_address)
                self.summarize_address.setText(summary_address)
                self.summarize_model.setText(summary_model)
                self.summarize_token.setText(summary_token)
                if self.uvr_file: self.uvr_file.setCurrentText(uvr_file)
                self.output_format.setCurrentText(output_format)

        if os.path.exists('whisper/param.txt'):
            with open('whisper/param.txt', 'r', encoding='utf-8') as f:
                self.param_whisper.setPlainText(f.read())

        if os.path.exists('whisper-faster/param.txt'):
            with open('whisper-faster/param.txt', 'r', encoding='utf-8') as f:
                self.param_whisper_faster.setPlainText(f.read())

        if os.path.exists('llama/param.txt'):
            with open('llama/param.txt', 'r', encoding='utf-8') as f:
                self.param_llama.setPlainText(f.read())

        if os.path.exists('project/dict_pre.txt'):
            with open('project/dict_pre.txt', 'r', encoding='utf-8') as f:
                self.before_dict.setPlainText(f.read())

        if os.path.exists('project/dict_gpt.txt'):
            with open('project/dict_gpt.txt', 'r', encoding='utf-8') as f:
                self.gpt_dict.setPlainText(f.read())

        if os.path.exists('project/dict_after.txt'):
            with open('project/dict_after.txt', 'r', encoding='utf-8') as f:
                self.after_dict.setPlainText(f.read())

        if os.path.exists('project/extra_prompt.txt'):
            with open('project/extra_prompt.txt', 'r', encoding='utf-8') as f:
                self.extra_prompt.setPlainText(f.read())

    def setup_timer(self):
        self.timer = QTimer(self)
        self.timer.timeout.connect(self.read_log_file)
        self.timer.start(1000)
        self.last_read_position = 0
        self.file_not_found_message_shown = False

    def read_log_file(self):
        """è¯»å–æ—¥å¿—æ–‡ä»¶å¹¶æ›´æ–°æ˜¾ç¤º"""
        try:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(LOG_PATH):
                if not self.file_not_found_message_shown:
                    timestamp = QDateTime.currentDateTime().toString("yyyy-MM-dd hh:mm:ss")
                    self.log_display.setPlainText(f"[{timestamp}] é”™è¯¯: æ—¥å¿—æ–‡ä»¶ '{LOG_PATH}' æœªæ‰¾åˆ°ã€‚æ­£åœ¨ç­‰å¾…æ–‡ä»¶åˆ›å»º...\n")
                    self.file_not_found_message_shown = True
                self.last_read_position = 0 # å¦‚æœæ–‡ä»¶æ¶ˆå¤±äº†ï¼Œé‡ç½®è¯»å–ä½ç½®
                return

            # å¦‚æœæ–‡ä»¶ä¹‹å‰æœªæ‰¾åˆ°ä½†ç°åœ¨æ‰¾åˆ°äº†
            if self.file_not_found_message_shown:
                self.log_display.clear() # æ¸…é™¤ä¹‹å‰çš„é”™è¯¯ä¿¡æ¯
                self.file_not_found_message_shown = False
                self.last_read_position = 0 # ä»å¤´å¼€å§‹è¯»

            with open(LOG_PATH, 'r', encoding='utf-8', errors='replace') as f:
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦è¢«æˆªæ–­æˆ–æ›¿æ¢ (ä¾‹å¦‚æ—¥å¿—è½®è½¬)
                # é€šè¿‡ seek(0, 2) è·å–å½“å‰æ–‡ä»¶å¤§å°
                current_file_size = f.seek(0, os.SEEK_END)
                if current_file_size < self.last_read_position:
                    # æ–‡ä»¶å˜å°äº†ï¼Œæ„å‘³ç€æ–‡ä»¶è¢«æˆªæ–­æˆ–æ›¿æ¢äº†
                    timestamp = QDateTime.currentDateTime().toString("yyyy-MM-dd hh:mm:ss")
                    self.log_display.appendPlainText(f"\n[{timestamp}] æ£€æµ‹åˆ°æ—¥å¿—æ–‡ä»¶æˆªæ–­æˆ–è½®è½¬ã€‚ä»å¤´å¼€å§‹è¯»å–...\n")
                    self.last_read_position = 0
                    # å¯ä»¥é€‰æ‹©æ¸…ç©ºæ˜¾ç¤º: self.log_display.clear()
                    # ä½†é€šå¸¸è¿½åŠ æç¤ºç„¶åä»å¤´è¯»æ–°å†…å®¹æ›´å¥½

                f.seek(self.last_read_position)
                new_content = f.read()
                if new_content:
                    self.log_display.appendPlainText(new_content) # appendPlainText ä¼šè‡ªåŠ¨å¤„ç†æ¢è¡Œ
                    # è‡ªåŠ¨æ»šåŠ¨åˆ°åº•éƒ¨
                    scrollbar = self.log_display.verticalScrollBar()
                    scrollbar.setValue(scrollbar.maximum())

                self.last_read_position = f.tell() # æ›´æ–°ä¸‹æ¬¡è¯»å–çš„èµ·å§‹ä½ç½®

        except FileNotFoundError: # è¿™ä¸ªç†è®ºä¸Šåœ¨ä¸Šé¢çš„ os.path.exists æ£€æŸ¥åä¸åº”é¢‘ç¹è§¦å‘
            if not self.file_not_found_message_shown:
                timestamp = QDateTime.currentDateTime().toString("yyyy-MM-dd hh:mm:ss")
                self.log_display.setPlainText(f"[{timestamp}] é”™è¯¯: æ—¥å¿—æ–‡ä»¶ '{LOG_PATH}' å†æ¬¡æ£€æŸ¥æ—¶æœªæ‰¾åˆ°ã€‚\n")
                self.file_not_found_message_shown = True
            self.last_read_position = 0
        except IOError as e:
            timestamp = QDateTime.currentDateTime().toString("yyyy-MM-dd hh:mm:ss")
            self.log_display.appendPlainText(f"[{timestamp}] è¯»å–æ—¥å¿—æ–‡ä»¶IOé”™è¯¯: {e}\n")
            # å¯ä»¥è€ƒè™‘åœ¨IOé”™è¯¯æ—¶åœæ­¢timeræˆ–åšå…¶ä»–å¤„ç†
        except Exception as e:
            timestamp = QDateTime.currentDateTime().toString("yyyy-MM-dd hh:mm:ss")
            self.log_display.appendPlainText(f"[{timestamp}] è¯»å–æ—¥å¿—æ–‡ä»¶æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}\n")

    def closeEvent(self, event):
        """ç¡®ä¿åœ¨å…³é—­çª—å£æ—¶åœæ­¢å®šæ—¶å™¨"""
        self.timer.stop()
        event.accept()

    def initLogTab(self):
        self.log_tab = Widget("Log", self)
        self.log_layout = self.log_tab.vBoxLayout
        self.log_layout.addWidget(BodyLabel("ğŸ“œ æ—¥å¿—æ–‡ä»¶"))

        # log
        self.log_display = QPlainTextEdit(self)
        self.log_display.setReadOnly(True)
        self.log_display.setStyleSheet("font-family: Consolas, Monospace; font-size: 10pt;") # è®¾ç½®ç­‰å®½å­—ä½“
        self.log_layout.addWidget(self.log_display)

        self.addSubInterface(self.log_tab, FluentIcon.INFO, "æ—¥å¿—", NavigationItemPosition.TOP)

    def initAboutTab(self):
        self.about_tab = Widget("About", self)
        self.about_layout = self.about_tab.vBoxLayout

        # introduce
        self.about_layout.addWidget(TitleLabel("ğŸ‰ æ„Ÿè°¢ä½¿ç”¨VoiceTranslï¼"))
        self.introduce_text = QTextEdit()
        self.introduce_text.setReadOnly(True)
        self.introduce_text.setPlainText(
"""
VoiceTranslï¼ˆåŸGaltransl for ASMRï¼‰æ˜¯ä¸€ä¸ªå¼€æºå…è´¹çš„ç¦»çº¿AIè§†é¢‘å­—å¹•ç”Ÿæˆå’Œç¿»è¯‘è½¯ä»¶ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨æœ¬ç¨‹åºä»å¤–è¯­éŸ³è§†é¢‘æ–‡ä»¶/å­—å¹•æ–‡ä»¶ç”Ÿæˆä¸­æ–‡å­—å¹•æ–‡ä»¶ã€‚

é¡¹ç›®åœ°å€åŠä½¿ç”¨è¯´æ˜: https://github.com/shinnpuru/VoiceTranslã€‚
Bç«™æ•™ç¨‹ï¼šhttps://space.bilibili.com/36464441/lists/3239068ã€‚
""")
        self.about_layout.addWidget(self.introduce_text)

        # mode
        self.about_layout.addWidget(TitleLabel("ğŸ”§ æ¨¡å¼è¯´æ˜"))
        self.mode_text = QTextEdit()
        self.mode_text.setReadOnly(True)
        self.mode_text.setPlainText(
"""
ï¼ˆ1ï¼‰ä»…ä¸‹è½½æ¨¡å¼ï¼šé€‰æ‹©ä¸è¿›è¡Œå¬å†™å’Œä¸è¿›è¡Œç¿»è¯‘ï¼›
ï¼ˆ2ï¼‰ä»…å¬å†™æ¨¡å¼ï¼šé€‰æ‹©å¬å†™æ¨¡å‹ï¼Œé€‰æ‹©ä¸è¿›è¡Œç¿»è¯‘ï¼›
ï¼ˆ3ï¼‰ä»…ç¿»è¯‘æ¨¡å¼ï¼šä¸Šä¼ SRTæ–‡ä»¶ï¼Œå¹¶ä¸”é€‰æ‹©ç¿»è¯‘æ¨¡å‹ï¼›  
ï¼ˆ4ï¼‰å®Œæ•´æ¨¡å¼ï¼šé€‰æ‹©æ‰€æœ‰åŠŸèƒ½ã€‚
""")
        self.about_layout.addWidget(self.mode_text)

        # disclaimer
        self.about_layout.addWidget(TitleLabel("ğŸ‡ æ”¯æŒæ˜•è’²"))
        self.disclaimer_text = QTextEdit()
        self.disclaimer_text.setReadOnly(True)
        self.disclaimer_text.setPlainText(
"""
å¦‚æœæ‚¨å–œæ¬¢è¿™ä¸ªé¡¹ç›®å¹¶å¸Œæœ›æ”¯æŒå¼€å‘ï¼Œæ¬¢è¿é€šè¿‡ä»¥ä¸‹æ–¹å¼èµåŠ©ï¼š
1. çˆ±å‘ç”µ: https://afdian.com/a/shinnpuruï¼ˆå¾®ä¿¡å’Œæ”¯ä»˜å®ï¼‰
2. Bç«™å……ç”µ: https://space.bilibili.com/36464441ï¼ˆå¤§ä¼šå‘˜å¯ç”¨å…è´¹Bå¸ï¼‰
3. Ko-fi: https://ko-fi.com/U7U018MISYï¼ˆPayPalåŠä¿¡ç”¨å¡ï¼‰
æ‚¨çš„æ”¯æŒå°†å¸®åŠ©æ˜•è’²æŒç»­æ”¹è¿›å’Œç»´æŠ¤è¿™ä¸ªé¡¹ç›®ï¼
""")
        self.about_layout.addWidget(self.disclaimer_text)

        # start
        self.start_button = QPushButton("ğŸš€ å¼€å§‹")
        self.start_button.clicked.connect(lambda: self.switchTo(self.input_output_tab))
        self.about_layout.addWidget(self.start_button)

        self.addSubInterface(self.about_tab, FluentIcon.HEART, "å…³äº", NavigationItemPosition.TOP)
        
    def initInputOutputTab(self):
        self.input_output_tab = Widget("Home", self)
        self.input_output_layout = self.input_output_tab.vBoxLayout
        
        # Input Section
        self.input_output_layout.addWidget(BodyLabel("ğŸ“‚ è¯·æ‹–æ‹½éŸ³è§†é¢‘æ–‡ä»¶/SRTæ–‡ä»¶åˆ°è¿™é‡Œï¼Œå¯å¤šé€‰ï¼Œè·¯å¾„è¯·å‹¿åŒ…å«éè‹±æ–‡å’Œç©ºæ ¼ã€‚"))
        self.input_files_list = QTextEdit()
        self.input_files_list.setAcceptDrops(True)
        self.input_files_list.dropEvent = lambda e: self.input_files_list.setPlainText('\n'.join([i[8:] for i in e.mimeData().text().split('\n')]))
        self.input_files_list.setPlaceholderText("å½“å‰æœªé€‰æ‹©æœ¬åœ°æ–‡ä»¶...")
        self.input_output_layout.addWidget(self.input_files_list)

        # YouTube URL Section
        self.input_output_layout.addWidget(BodyLabel("ğŸ”— æˆ–è€…è¾“å…¥Bç«™è§†é¢‘BVå·æˆ–è€…YouTubeåŠå…¶ä»–è§†é¢‘é“¾æ¥ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰ã€‚"))
        self.yt_url = QTextEdit()
        self.yt_url.setAcceptDrops(False)
        self.yt_url.setPlaceholderText("ä¾‹å¦‚ï¼šhttps://www.youtube.com/watch?v=...\nä¾‹å¦‚ï¼šBV1Lxt5e8EJF")
        self.input_output_layout.addWidget(self.yt_url)

        # Proxy Section
        self.input_output_layout.addWidget(BodyLabel("ğŸŒ è®¾ç½®ä»£ç†åœ°å€ä»¥ä¾¿ä¸‹è½½è§†é¢‘å’Œç¿»è¯‘ã€‚"))
        self.proxy_address = QLineEdit()
        self.proxy_address.setPlaceholderText("ä¾‹å¦‚ï¼šhttp://127.0.0.1:7890ï¼Œç•™ç©ºä¸ºä¸ä½¿ç”¨")
        self.input_output_layout.addWidget(self.proxy_address)

        # Format Section
        self.input_output_layout.addWidget(BodyLabel("ğŸ¥ é€‰æ‹©è¾“å‡ºçš„å­—å¹•æ ¼å¼ã€‚"))
        self.output_format = QComboBox()
        self.output_format.addItems(['åŸæ–‡SRT', 'ä¸­æ–‡LRC', 'ä¸­æ–‡SRT', 'åŒè¯­SRT'])
        self.output_format.setCurrentText('ä¸­æ–‡SRT')
        self.input_output_layout.addWidget(self.output_format)

        self.run_button = QPushButton("ğŸš€ è¿è¡Œ")
        self.run_button.clicked.connect(self.run_worker)
        self.input_output_layout.addWidget(self.run_button)

        self.output_text_edit = QTextEdit()
        self.output_text_edit.setReadOnly(True)
        self.output_text_edit.setPlaceholderText("å½“å‰æ— è¾“å‡ºä¿¡æ¯...")
        self.status.connect(self.output_text_edit.append)
        self.input_output_layout.addWidget(self.output_text_edit)

        self.open_output_button = QPushButton("ğŸ“ æ‰“å¼€ä¸‹è½½å’Œç¼“å­˜æ–‡ä»¶å¤¹")
        self.open_output_button.clicked.connect(lambda: os.startfile(os.path.join(os.getcwd(),'project/cache')))
        self.input_output_layout.addWidget(self.open_output_button)
        
        self.clean_button = QPushButton("ğŸ§¹ æ¸…ç©ºä¸‹è½½å’Œç¼“å­˜")
        self.clean_button.clicked.connect(self.cleaner)
        self.input_output_layout.addWidget(self.clean_button)
        
        self.addSubInterface(self.input_output_tab, FluentIcon.HOME, "ä¸»é¡µ", NavigationItemPosition.TOP)

    def initDictTab(self):
        self.dict_tab = Widget("Dict", self)
        self.dict_layout = self.dict_tab.vBoxLayout

        self.dict_layout.addWidget(BodyLabel("ğŸ“š é…ç½®ç¿»è¯‘å‰çš„å­—å…¸ã€‚"))
        self.before_dict = QTextEdit()
        self.before_dict.setPlaceholderText("æ—¥æ–‡åŸæ–‡(Tabé”®)æ—¥æ–‡æ›¿æ¢è¯\næ—¥æ–‡åŸæ–‡(Tabé”®)æ—¥æ–‡æ›¿æ¢è¯")
        self.dict_layout.addWidget(self.before_dict)
        
        self.dict_layout.addWidget(BodyLabel("ğŸ“š é…ç½®ç¿»è¯‘ä¸­çš„å­—å…¸ã€‚"))
        self.gpt_dict = QTextEdit()
        self.gpt_dict.setPlaceholderText("æ—¥æ–‡(Tabé”®)ä¸­æ–‡\næ—¥æ–‡(Tabé”®)ä¸­æ–‡")
        self.dict_layout.addWidget(self.gpt_dict)
        
        self.dict_layout.addWidget(BodyLabel("ğŸ“š é…ç½®ç¿»è¯‘åçš„å­—å…¸ã€‚"))
        self.after_dict = QTextEdit()
        self.after_dict.setPlaceholderText("ä¸­æ–‡åŸæ–‡(Tabé”®)ä¸­æ–‡æ›¿æ¢è¯\nä¸­æ–‡åŸæ–‡(Tabé”®)ä¸­æ–‡æ›¿æ¢è¯")
        self.dict_layout.addWidget(self.after_dict)

        self.dict_layout.addWidget(BodyLabel("ğŸ“• é…ç½®é¢å¤–æç¤ºã€‚"))
        self.extra_prompt = QTextEdit()
        self.extra_prompt.setPlaceholderText("è¯·åœ¨è¿™é‡Œè¾“å…¥é¢å¤–çš„æç¤ºä¿¡æ¯ï¼Œä¾‹å¦‚ä¸–ç•Œä¹¦æˆ–å°æœ¬å†…å®¹ã€‚")
        self.dict_layout.addWidget(self.extra_prompt)

        self.addSubInterface(self.dict_tab, FluentIcon.DICTIONARY, "å­—å…¸è®¾ç½®", NavigationItemPosition.TOP)
        
    def initSettingsTab(self):
        self.settings_tab = Widget("Settings", self)
        self.settings_layout = self.settings_tab.vBoxLayout
        
        # Whisper Section
        self.settings_layout.addWidget(BodyLabel("ğŸ—£ï¸ é€‰æ‹©ç”¨äºè¯­éŸ³è¯†åˆ«çš„æ¨¡å‹æ–‡ä»¶ã€‚"))
        self.whisper_file = QComboBox()
        whisper_lst = [i for i in os.listdir('whisper') if i.startswith('ggml') and i.endswith('bin')] + [i for i in os.listdir('whisper-faster') if i.startswith('faster-whisper')] + ['ä¸è¿›è¡Œå¬å†™']
        self.whisper_file.addItems(whisper_lst)
        self.settings_layout.addWidget(self.whisper_file)

        self.settings_layout.addWidget(BodyLabel("ğŸŒ é€‰æ‹©è¾“å…¥çš„è¯­è¨€ã€‚(ja=æ—¥è¯­ï¼Œen=è‹±è¯­ï¼Œko=éŸ©è¯­ï¼Œru=ä¿„è¯­ï¼Œfr=æ³•è¯­ï¼Œzh=ä¸­æ–‡ï¼Œä»…å¬å†™ï¼‰"))
        self.input_lang = QComboBox()
        self.input_lang.addItems(['ja','en','ko','ru','fr','zh'])
        self.settings_layout.addWidget(self.input_lang)

        self.open_whisper_dir = QPushButton("ğŸ“ æ‰“å¼€Whisperç›®å½•")
        self.open_whisper_dir.clicked.connect(lambda: os.startfile(os.path.join(os.getcwd(),'whisper')))
        self.open_faster_dir = QPushButton("ğŸ“ æ‰“å¼€Faster Whisperç›®å½•")
        self.open_faster_dir.clicked.connect(lambda: os.startfile(os.path.join(os.getcwd(),'whisper-faster')))
        self.settings_layout.addWidget(self.open_whisper_dir)
        self.settings_layout.addWidget(self.open_faster_dir)

        self.settings_layout.addWidget(BodyLabel("ğŸ”§ è¾“å…¥Whisperå‘½ä»¤è¡Œå‚æ•°ã€‚"))
        self.param_whisper = QTextEdit()
        self.param_whisper.setPlaceholderText("æ¯ä¸ªå‚æ•°ç©ºæ ¼éš”å¼€ï¼Œè¯·å‚è€ƒWhisper.cppï¼Œä¸æ¸…æ¥šè¯·ä¿æŒé»˜è®¤ã€‚")
        self.settings_layout.addWidget(self.param_whisper)

        self.settings_layout.addWidget(BodyLabel("ğŸ”§ è¾“å…¥Whisper-Fasterå‘½ä»¤è¡Œå‚æ•°ã€‚"))
        self.param_whisper_faster = QTextEdit()
        self.param_whisper_faster.setPlaceholderText("æ¯ä¸ªå‚æ•°ç©ºæ ¼éš”å¼€ï¼Œè¯·å‚è€ƒFaster Whisperæ–‡æ¡£ï¼Œä¸æ¸…æ¥šè¯·ä¿æŒé»˜è®¤ã€‚")
        self.settings_layout.addWidget(self.param_whisper_faster)

        self.addSubInterface(self.settings_tab, FluentIcon.MUSIC, "å¬å†™è®¾ç½®", NavigationItemPosition.TOP)

    def initAdvancedSettingTab(self):
        self.advanced_settings_tab = Widget("AdvancedSettings", self)
        self.advanced_settings_layout = self.advanced_settings_tab.vBoxLayout

        # Translator Section
        self.advanced_settings_layout.addWidget(BodyLabel("ğŸš€ é€‰æ‹©ç”¨äºç¿»è¯‘çš„æ¨¡å‹ç±»åˆ«ã€‚"))
        self.translator_group = QComboBox()
        self.translator_group.addItems(TRANSLATOR_SUPPORTED)
        self.advanced_settings_layout.addWidget(self.translator_group)
        
        self.advanced_settings_layout.addWidget(BodyLabel("ğŸš€ åœ¨çº¿æ¨¡å‹ä»¤ç‰Œ"))
        self.gpt_token = QLineEdit()
        self.gpt_token.setPlaceholderText("ç•™ç©ºä¸ºä½¿ç”¨ä¸Šæ¬¡é…ç½®çš„Tokenã€‚")
        self.advanced_settings_layout.addWidget(self.gpt_token)

        self.advanced_settings_layout.addWidget(BodyLabel("ğŸš€ åœ¨çº¿æ¨¡å‹åç§°"))
        self.gpt_model = QLineEdit()
        self.gpt_model.setPlaceholderText("ä¾‹å¦‚ï¼šdeepseek-chat")
        self.advanced_settings_layout.addWidget(self.gpt_model)

        self.advanced_settings_layout.addWidget(BodyLabel("ğŸš€ è‡ªå®šä¹‰APIåœ°å€ï¼ˆgpt-customï¼‰"))
        self.gpt_address = QLineEdit()
        self.gpt_address.setPlaceholderText("ä¾‹å¦‚ï¼šhttp://127.0.0.1:11434")
        self.advanced_settings_layout.addWidget(self.gpt_address)
        
        self.advanced_settings_layout.addWidget(BodyLabel("ğŸ’» ç¦»çº¿æ¨¡å‹æ–‡ä»¶ï¼ˆgaltranslï¼Œ sakuraï¼Œllamacppï¼‰"))
        self.sakura_file = QComboBox()
        sakura_lst = [i for i in os.listdir('llama') if i.endswith('gguf')]
        self.sakura_file.addItems(sakura_lst)
        self.advanced_settings_layout.addWidget(self.sakura_file)
        
        self.advanced_settings_layout.addWidget(BodyLabel("ğŸ’» ç¦»çº¿æ¨¡å‹å‚æ•°ï¼ˆgaltranslï¼Œ sakuraï¼Œllamacppï¼‰"))
        self.sakura_value = QLineEdit()
        self.sakura_value.setPlaceholderText("100")
        self.sakura_value.setReadOnly(True)
        self.advanced_settings_layout.addWidget(self.sakura_value)
        self.sakura_mode = QSlider(Qt.Horizontal)
        self.sakura_mode.setRange(0, 100)
        self.sakura_mode.setValue(100)
        self.sakura_mode.valueChanged.connect(lambda: self.sakura_value.setText(str(self.sakura_mode.value())))
        self.advanced_settings_layout.addWidget(self.sakura_mode)

        self.open_model_dir = QPushButton("ğŸ“ æ‰“å¼€ç¦»çº¿æ¨¡å‹ç›®å½•")
        self.open_model_dir.clicked.connect(lambda: os.startfile(os.path.join(os.getcwd(),'llama')))
        self.advanced_settings_layout.addWidget(self.open_model_dir)

        self.advanced_settings_layout.addWidget(BodyLabel("ğŸ”§ è¾“å…¥Llama.cppå‘½ä»¤è¡Œå‚æ•°ã€‚"))
        self.param_llama = QTextEdit()
        self.param_llama.setPlaceholderText("æ¯ä¸ªå‚æ•°ç©ºæ ¼éš”å¼€ï¼Œè¯·å‚è€ƒLlama.cppæ–‡æ¡£ï¼Œä¸æ¸…æ¥šè¯·ä¿æŒé»˜è®¤ã€‚")
        self.advanced_settings_layout.addWidget(self.param_llama)

        self.addSubInterface(self.advanced_settings_tab, FluentIcon.BOOK_SHELF, "ç¿»è¯‘è®¾ç½®", NavigationItemPosition.TOP)

    def initClipTab(self):
        self.clip_tab = Widget("Clip", self)
        self.clip_layout = self.clip_tab.vBoxLayout

        # Split Section
        self.clip_layout.addWidget(BodyLabel("ğŸ”ª åˆ†å‰²åˆå¹¶å·¥å…·"))
        self.split_value = QLineEdit()
        self.split_value.setPlaceholderText("600")
        self.split_value.setReadOnly(True)
        self.clip_layout.addWidget(self.split_value)
        self.split_mode = QSlider(Qt.Horizontal)
        self.split_mode.setRange(0, 3600)
        self.split_mode.setValue(600)
        self.split_mode.valueChanged.connect(lambda: self.split_value.setText(str(self.split_mode.value())))
        self.clip_layout.addWidget(self.split_mode)

        self.split_files_list = QTextEdit()
        self.split_files_list.setAcceptDrops(True)
        self.split_files_list.dropEvent = lambda e: self.split_files_list.setPlainText('\n'.join([i[8:] for i in e.mimeData().text().split('\n')]))
        self.split_files_list.setPlaceholderText("æ‹–æ‹½æ–‡ä»¶åˆ°æ–¹æ¡†å†…ï¼Œç‚¹å‡»è¿è¡Œå³å¯ï¼Œæ¯ä¸ªæ–‡ä»¶ç”Ÿæˆä¸€ä¸ªæ–‡ä»¶å¤¹ï¼Œæ»‘åŠ¨æ¡æ•°å­—ä»£è¡¨åˆ‡å‰²æ¯æ®µéŸ³é¢‘çš„é•¿åº¦ï¼ˆç§’ï¼‰ã€‚")
        self.clip_layout.addWidget(self.split_files_list)
        self.run_split_button = QPushButton("ğŸš€ åˆ†å‰²")
        self.run_split_button.clicked.connect(self.run_split)
        self.clip_layout.addWidget(self.run_split_button)

        self.merge_files_list = QTextEdit()
        self.merge_files_list.setAcceptDrops(True)
        self.merge_files_list.dropEvent = lambda e: self.merge_files_list.setPlainText('\n'.join([i[8:] for i in e.mimeData().text().split('\n')]))
        self.merge_files_list.setPlaceholderText("æ‹–æ‹½å¤šä¸ªå­—å¹•æ–‡ä»¶åˆ°æ–¹æ¡†å†…ï¼Œç‚¹å‡»è¿è¡Œå³å¯ï¼Œæ¯æ¬¡åˆå¹¶æˆä¸€ä¸ªæ–‡ä»¶ã€‚æ—¶é—´æˆ³æŒ‰ç…§ä¸Šé¢æ»‘åŠ¨æ¡åˆ†å‰²çš„æ—¶é—´ç´¯åŠ ã€‚")
        self.clip_layout.addWidget(self.merge_files_list)
        self.run_merge_button = QPushButton("ğŸš€ åˆå¹¶")
        self.run_merge_button.clicked.connect(self.run_merge)
        self.clip_layout.addWidget(self.run_merge_button)

        # Clip Section
        self.clip_layout.addWidget(BodyLabel("âœ‚ï¸ åˆ‡ç‰‡å·¥å…·"))
        self.clip_files_list = QTextEdit()
        self.clip_files_list.setAcceptDrops(True)
        self.clip_files_list.dropEvent = lambda e: self.clip_files_list.setPlainText('\n'.join([i[8:] for i in e.mimeData().text().split('\n')]))
        self.clip_files_list.setPlaceholderText("æ‹–æ‹½è§†é¢‘æ–‡ä»¶åˆ°æ–¹æ¡†å†…ï¼Œå¹¶å¡«å†™å¼€å§‹å’Œç»“æŸæ—¶é—´ï¼Œç‚¹å‡»è¿è¡Œå³å¯ã€‚")
        self.clip_layout.addWidget(self.clip_files_list)
        self.clip_start_time = QLineEdit()
        self.clip_start_time.setPlaceholderText("å¼€å§‹æ—¶é—´ï¼ˆHH:MM:SS.xxxï¼‰")
        self.clip_layout.addWidget(self.clip_start_time)
        self.clip_end_time = QLineEdit()
        self.clip_end_time.setPlaceholderText("ç»“æŸæ—¶é—´ï¼ˆHH:MM:SS.xxxï¼‰")
        self.clip_layout.addWidget(self.clip_end_time)
        self.run_clip_button = QPushButton("ğŸš€ åˆ‡ç‰‡")
        self.run_clip_button.clicked.connect(self.run_clip)
        self.clip_layout.addWidget(self.run_clip_button)
        
        self.addSubInterface(self.clip_tab, FluentIcon.TILES, "åˆ†å‰²å·¥å…·", NavigationItemPosition.TOP)

    def initSynthTab(self):
        self.synth_tab = Widget("Synth", self)
        self.synth_layout = self.synth_tab.vBoxLayout

        # Vocal Split
        self.synth_layout.addWidget(BodyLabel("ğŸ¤ äººå£°åˆ†ç¦»å·¥å…·"))
        self.synth_layout.addWidget(BodyLabel("é€‰æ‹©ç”¨äºä¼´å¥åˆ†ç¦»çš„æ¨¡å‹æ–‡ä»¶ã€‚"))
        self.uvr_file = QComboBox()
        uvr_lst = [i for i in os.listdir('uvr') if i.endswith('onnx')]
        self.uvr_file.addItems(uvr_lst)
        self.synth_layout.addWidget(self.uvr_file)
        self.open_uvr_dir = QPushButton("ğŸ“ æ‰“å¼€UVRæ¨¡å‹ç›®å½•")
        self.open_uvr_dir.clicked.connect(lambda: os.startfile(os.path.join(os.getcwd(),'uvr')))
        self.synth_layout.addWidget(self.open_uvr_dir)


        self.uvr_file_list = QTextEdit()
        self.uvr_file_list.setAcceptDrops(True)
        self.uvr_file_list.dropEvent = lambda e: self.uvr_file_list.setPlainText('\n'.join([i[8:] for i in e.mimeData().text().split('\n')]))
        self.uvr_file_list.setPlaceholderText("æ‹–æ‹½éŸ³é¢‘æ–‡ä»¶åˆ°æ–¹æ¡†å†…ï¼Œç‚¹å‡»è¿è¡Œå³å¯ã€‚è¾“å‡ºæ–‡ä»¶ä¸ºåŸæ–‡ä»¶å_vocal.wavå’Œ_no_vocal.wavã€‚")
        self.synth_layout.addWidget(self.uvr_file_list)

        self.run_uvr_button = QPushButton("ğŸš€ äººå£°åˆ†ç¦»")
        self.run_uvr_button.clicked.connect(self.run_vocal_split)
        self.synth_layout.addWidget(self.run_uvr_button)

        # Video Synth
        self.synth_layout.addWidget(BodyLabel("ğŸ’¾ å­—å¹•åˆæˆå·¥å…·"))
        self.synth_files_list = QTextEdit()
        self.synth_files_list.setAcceptDrops(True)
        self.synth_files_list.dropEvent = lambda e: self.synth_files_list.setPlainText('\n'.join([i[8:] for i in e.mimeData().text().split('\n')]))
        self.synth_files_list.setPlaceholderText("æ‹–æ‹½å­—å¹•æ–‡ä»¶å’Œè§†é¢‘æ–‡ä»¶åˆ°ä¸‹æ–¹æ¡†å†…ï¼Œç‚¹å‡»è¿è¡Œå³å¯ã€‚å­—å¹•å’Œè§†é¢‘æ–‡ä»¶éœ€è¦ä¸€ä¸€å¯¹åº”ï¼Œä¾‹å¦‚output.mp4å’Œoutput.mp4.srtã€‚")
        self.synth_layout.addWidget(self.synth_files_list)
        self.run_synth_button = QPushButton("ğŸš€ å­—å¹•åˆæˆ")
        self.run_synth_button.clicked.connect(self.run_synth)
        self.synth_layout.addWidget(self.run_synth_button)

        # Audio Synth
        self.synth_layout.addWidget(BodyLabel("ğŸµ éŸ³é¢‘åˆæˆå·¥å…·"))
        self.synth_audio_files_list = QTextEdit()
        self.synth_audio_files_list.setAcceptDrops(True)
        self.synth_audio_files_list.dropEvent = lambda e: self.synth_audio_files_list.setPlainText('\n'.join([i[8:] for i in e.mimeData().text().split('\n')]))
        self.synth_audio_files_list.setPlaceholderText("æ‹–æ‹½éŸ³é¢‘æ–‡ä»¶ï¼ˆwavï¼Œmp3ï¼Œflacï¼‰å’Œå›¾åƒï¼ˆpng,jpg,jpegï¼‰åˆ°ä¸‹æ–¹æ¡†å†…ï¼Œç‚¹å‡»è¿è¡Œå³å¯ã€‚éŸ³é¢‘å’Œå›¾åƒæ–‡ä»¶éœ€è¦ä¸€ä¸€å¯¹åº”ã€‚")
        self.synth_layout.addWidget(self.synth_audio_files_list)
        self.run_synth_audio_button = QPushButton("ğŸš€ è§†é¢‘åˆæˆ")
        self.run_synth_audio_button.clicked.connect(self.run_synth_audio)
        self.synth_layout.addWidget(self.run_synth_audio_button)

        self.addSubInterface(self.synth_tab, FluentIcon.DEVELOPER_TOOLS, "åˆæˆå·¥å…·", NavigationItemPosition.TOP)

    def initSummarizeTab(self):
        self.summarize_tab = Widget("Summarize", self)
        self.summarize_layout = self.summarize_tab.vBoxLayout

        self.summarize_layout.addWidget(BodyLabel("ğŸŒ OpenAIå…¼å®¹åœ°å€"))
        self.summarize_address = QLineEdit()
        self.summarize_address.setPlaceholderText("ä¾‹å¦‚ï¼šhttps://api.deepseek.com/v1")
        self.summarize_layout.addWidget(self.summarize_address)

        self.summarize_layout.addWidget(BodyLabel("ğŸš© æ¨¡å‹åç§°"))
        self.summarize_model = QLineEdit()
        self.summarize_model.setPlaceholderText("ä¾‹å¦‚ï¼šdeepseek-chat")
        self.summarize_layout.addWidget(self.summarize_model)

        self.summarize_layout.addWidget(BodyLabel("ğŸ“› æ¨¡å‹ä»¤ç‰Œ"))
        self.summarize_token = QLineEdit()
        self.summarize_layout.addWidget(self.summarize_token)

        self.summarize_layout.addWidget(BodyLabel("ğŸ–‹ï¸ æ¨¡å‹æç¤º"))
        self.summarize_prompt = QTextEdit()
        self.summarize_prompt.setPlaceholderText("è¯·ä¸ºä»¥ä¸‹å†…å®¹åˆ›å»ºä¸€ä¸ªå¸¦æœ‰æ—¶é—´æˆ³ï¼ˆmm:ssæ ¼å¼ï¼‰çš„ç²—ç•¥æ‘˜è¦ï¼Œä¸å¤šäº10ä¸ªäº‹ä»¶ã€‚è¯·å…³æ³¨å…³é”®äº‹ä»¶å’Œé‡è¦æ—¶åˆ»ï¼Œå¹¶ç¡®ä¿æ‰€æœ‰æ—¶é—´æˆ³éƒ½é‡‡ç”¨åˆ†é’Ÿ:ç§’é’Ÿæ ¼å¼ã€‚")
        self.summarize_layout.addWidget(self.summarize_prompt)

        self.summarize_layout.addWidget(BodyLabel("ğŸ“ è¾“å…¥æ–‡ä»¶"))
        self.summarize_files_list = QTextEdit()
        self.summarize_files_list.setAcceptDrops(True)
        self.summarize_files_list.dropEvent = lambda e: self.summarize_files_list.setPlainText('\n'.join([i[8:] for i in e.mimeData().text().split('\n')]))
        self.summarize_files_list.setPlaceholderText("æ‹–æ‹½æ–‡ä»¶åˆ°æ–¹æ¡†å†…ï¼Œç‚¹å‡»è¿è¡Œå³å¯ã€‚è¾“å‡ºæ–‡ä»¶ä¸ºè¾“å…¥æ–‡ä»¶å.summary.txtã€‚")
        self.summarize_layout.addWidget(self.summarize_files_list)

        self.run_summarize_button = QPushButton("ğŸš€ è¿è¡Œ")
        self.run_summarize_button.clicked.connect(self.run_summarize)
        self.summarize_layout.addWidget(self.run_summarize_button)

        self.addSubInterface(self.summarize_tab, FluentIcon.EDUCATION, "å­—å¹•æ€»ç»“", NavigationItemPosition.TOP)
        
    def select_input(self):
        options = QFileDialog.Options()
        files, _ = QFileDialog.getOpenFileNames(self, "é€‰æ‹©éŸ³è§†é¢‘æ–‡ä»¶/SRTæ–‡ä»¶", "", "All Files (*);;Video Files (*.mp4 *.webm, *.flv);;SRT Files (*.srt);;Audio Files (*.wav, *.mp3, *.flac)", options=options)
        if files:
            self.input_files_list.setPlainText('\n'.join(files))

    def run_worker(self):
        self.thread = QThread()
        self.worker = MainWorker(self)
        self.worker.moveToThread(self.thread)
        self.thread.started.connect(self.worker.run)
        self.worker.finished.connect(self.thread.quit)
        self.thread.start()

    def run_split(self):
        self.thread = QThread()
        self.worker = MainWorker(self)
        self.worker.moveToThread(self.thread)
        self.thread.started.connect(self.worker.split)
        self.worker.finished.connect(self.thread.quit)
        self.thread.start()

    def run_merge(self):
        self.thread = QThread()
        self.worker = MainWorker(self)
        self.worker.moveToThread(self.thread)
        self.thread.started.connect(self.worker.merge)
        self.worker.finished.connect(self.thread.quit)
        self.thread.start()

    def run_clip(self):
        self.thread = QThread()
        self.worker = MainWorker(self)
        self.worker.moveToThread(self.thread)
        self.thread.started.connect(self.worker.clip)
        self.worker.finished.connect(self.thread.quit)
        self.thread.start()

    def run_synth(self):
        self.thread = QThread()
        self.worker = MainWorker(self)
        self.worker.moveToThread(self.thread)
        self.thread.started.connect(self.worker.synth)
        self.worker.finished.connect(self.thread.quit)
        self.thread.start()

    def run_synth_audio(self):
        self.thread = QThread()
        self.worker = MainWorker(self)
        self.worker.moveToThread(self.thread)
        self.thread.started.connect(self.worker.audiosynth)
        self.worker.finished.connect(self.thread.quit)
        self.thread.start()

    def run_vocal_split(self):
        self.thread = QThread()
        self.worker = MainWorker(self)
        self.worker.moveToThread(self.thread)
        self.thread.started.connect(self.worker.vocal_split)
        self.worker.finished.connect(self.thread.quit)
        self.thread.start()

    def run_summarize(self):
        self.thread = QThread()
        self.worker = MainWorker(self)
        self.worker.moveToThread(self.thread)
        self.thread.started.connect(self.worker.summarize)
        self.worker.finished.connect(self.thread.quit)
        self.thread.start()
    
    def cleaner(self):
        self.status.emit("[INFO] æ­£åœ¨æ¸…ç†ä¸­é—´æ–‡ä»¶...")
        if os.path.exists('project/gt_input'):
            shutil.rmtree('project/gt_input')
        if os.path.exists('project/gt_output'):
            shutil.rmtree('project/gt_output')
        if os.path.exists('project/transl_cache'):
            shutil.rmtree('project/transl_cache')
        self.status.emit("[INFO] æ­£åœ¨æ¸…ç†è¾“å‡º...")
        if os.path.exists('project/cache'):
            shutil.rmtree('project/cache')
        os.makedirs('project/cache', exist_ok=True)

def error_handler(func):
    def wrapper(self):
        try:
            func(self)
        except Exception as e:
            self.status.emit(f"[ERROR] {e}")
            self.finished.emit()
    return wrapper
class MainWorker(QObject):
    finished = pyqtSignal()

    def __init__(self, master):
        super().__init__()
        self.master = master
        self.status = master.status

    @error_handler
    def save_config(self):
        self.status.emit("[INFO] æ­£åœ¨è¯»å–é…ç½®...")
        whisper_file = self.master.whisper_file.currentText()
        translator = self.master.translator_group.currentText()
        language = self.master.input_lang.currentText()
        gpt_token = self.master.gpt_token.text()
        gpt_address = self.master.gpt_address.text()
        gpt_model = self.master.gpt_model.text()
        sakura_file = self.master.sakura_file.currentText()
        sakura_mode = self.master.sakura_mode.value()
        proxy_address = self.master.proxy_address.text()
        summary_address = self.master.summarize_address.text()
        summary_model = self.master.summarize_model.text()
        summary_token = self.master.summarize_token.text()
        uvr_file = self.master.uvr_file.currentText()
        output_format = self.master.output_format.currentText()

        # save config
        with open('config.txt', 'w', encoding='utf-8') as f:
            f.write(f"{whisper_file}\n{translator}\n{language}\n{gpt_token}\n{gpt_address}\n{gpt_model}\n{sakura_file}\n{sakura_mode}\n{proxy_address}\n{summary_address}\n{summary_model}\n{summary_token}\n{uvr_file}\n{output_format}\n")

        # save whisper param
        with open('whisper/param.txt', 'w', encoding='utf-8') as f:
            f.write(self.master.param_whisper.toPlainText())

        # save llama param
        with open('llama/param.txt', 'w', encoding='utf-8') as f:
            f.write(self.master.param_llama.toPlainText())

        # save before dict
        with open('project/dict_pre.txt', 'w', encoding='utf-8') as f:
            f.write(self.master.before_dict.toPlainText())

        # save gpt dict
        with open('project/dict_gpt.txt', 'w', encoding='utf-8') as f:
            f.write(self.master.gpt_dict.toPlainText())

        # save after dict
        with open('project/dict_after.txt', 'w', encoding='utf-8') as f:
            f.write(self.master.after_dict.toPlainText())

        self.status.emit("[INFO] é…ç½®ä¿å­˜å®Œæˆï¼")

    @error_handler
    def vocal_split(self):
        self.save_config()
        uvr_file = self.master.uvr_file.currentText()
        if not uvr_file.endswith('.onnx'):
            self.status.emit("[ERROR] è¯·é€‰æ‹©æ­£ç¡®çš„UVRæ¨¡å‹æ–‡ä»¶ï¼")
            self.finished.emit()
            return

        input_files = self.master.uvr_file_list.toPlainText()
        if input_files:
            input_files = input_files.strip().split('\n')
            for idx, input_file in enumerate(input_files):
                if not os.path.exists(input_file):
                    self.status.emit(f"[ERROR] {input_file}æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·é‡æ–°é€‰æ‹©æ–‡ä»¶ï¼")
                    self.finished.emit()

                self.status.emit(f"[INFO] æ­£åœ¨è¿›è¡Œä¼´å¥åˆ†ç¦»...ç¬¬{idx+1}ä¸ªï¼Œå…±{len(input_files)}ä¸ª")
                self.pid = subprocess.Popen(['uvr/separate.exe', '-m', os.path.join('uvr',uvr_file), input_file], stdout=sys.stdout, stderr=sys.stdout, creationflags=0x08000000)
                self.pid.wait()
                self.pid.kill()
                self.pid.terminate()

            self.status.emit("[INFO] æ–‡ä»¶å¤„ç†å®Œæˆï¼")
        self.finished.emit()

    @error_handler
    def summarize(self):
        self.save_config()
        input_files = self.master.summarize_files_list.toPlainText()
        address = self.master.summarize_address.text()
        model = self.master.summarize_model.text()
        token = self.master.summarize_token.text()
        prompt = self.master.summarize_prompt.toPlainText()
        if input_files:
            input_files = input_files.strip().split('\n')
            for idx, input_file in enumerate(input_files):
                if not os.path.exists(input_file):
                    self.status.emit(f"[ERROR] {input_file}æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·é‡æ–°é€‰æ‹©æ–‡ä»¶ï¼")
                    self.finished.emit()

                from summarize import summarize
                self.status.emit(f"[INFO] æ­£åœ¨è¿›è¡Œæ–‡æœ¬æ‘˜è¦...ç¬¬{idx+1}ä¸ªï¼Œå…±{len(input_files)}ä¸ª")
                summarize(input_file, address, model, token, prompt)
            self.status.emit("[INFO] æ–‡ä»¶å¤„ç†å®Œæˆï¼")
        self.finished.emit()

    @error_handler
    def split(self):
        self.save_config()
        input_files = self.master.split_files_list.toPlainText()
        split_mode = self.master.split_mode.value()
        if input_files:
            input_files = input_files.strip().split('\n')
            for idx, input_file in enumerate(input_files):
                if not os.path.exists(input_file):
                    self.status.emit(f"[ERROR] {input_file}æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·é‡æ–°é€‰æ‹©æ–‡ä»¶ï¼")
                    self.finished.emit()

                self.status.emit(f"[INFO] å½“å‰å¤„ç†æ–‡ä»¶ï¼š{input_file} ç¬¬{idx+1}ä¸ªï¼Œå…±{len(input_files)}ä¸ª")
                os.makedirs(os.path.join(*(input_file.split('.')[:-1])), exist_ok=True)

                self.status.emit(f"[INFO] æ­£åœ¨è¿›è¡ŒéŸ³é¢‘æå–...æ¯{split_mode}ç§’åˆ†å‰²ä¸€æ¬¡")
                self.pid = subprocess.Popen(['ffmpeg', '-y', '-i', input_file,  '-f', 'segment', '-segment_time', str(split_mode), '-acodec', 'pcm_s16le', '-ac', '1', '-ar', '16000', os.path.join(*(input_file.split('.')[:-1]+['%04d.wav']))], stdout=sys.stdout, stderr=sys.stdout, creationflags=0x08000000)
                self.pid.wait()
                self.pid.kill()
                self.pid.terminate()
                self.status.emit("[INFO] éŸ³é¢‘åˆ†å‰²å®Œæˆï¼")
        self.finished.emit()

    @error_handler
    def merge(self):
        self.save_config()
        input_files = self.master.merge_files_list.toPlainText()
        split_mode = self.master.split_mode.value()
        if input_files:
            input_files = sorted(input_files.strip().split('\n'))
            merged_prompt = []
            for idx, input_file in enumerate(input_files):
                if not os.path.exists(input_file):
                    self.status.emit(f"[ERROR] {input_file}æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·é‡æ–°é€‰æ‹©æ–‡ä»¶ï¼")
                    self.finished.emit()

                self.status.emit(f"[INFO] å½“å‰å¤„ç†æ–‡ä»¶ï¼š{input_file} ç¬¬{idx+1}ä¸ªï¼Œå…±{len(input_files)}ä¸ª")
                prompt = make_prompt(input_file)

                for i in prompt:
                    i['start'] += idx * split_mode
                    i['end'] += idx * split_mode
                    merged_prompt.append(i)

            with open(input_files[0].replace('.srt','_merged.json'), 'w', encoding='utf-8') as f:
                json.dump(merged_prompt, f, ensure_ascii=False, indent=4)
            make_srt(input_files[0].replace('.srt','_merged.json'), input_files[0].replace('.srt','_merged.srt'))
            self.status.emit("[INFO] æ‰€æœ‰æ–‡ä»¶å¤„ç†å®Œæˆï¼")
        self.finished.emit()

    @error_handler
    def synth(self):
        self.save_config()
        input_files = self.master.synth_files_list.toPlainText()
        if input_files:
            input_files = input_files.strip().split('\n')
            srt_files = sorted([i for i in input_files if i.endswith('.srt')])
            video_files = sorted([i for i in input_files if not i.endswith('.srt')])
            if len(srt_files) != len(video_files):
                self.status.emit("[ERROR] å­—å¹•æ–‡ä»¶å’Œè§†é¢‘æ–‡ä»¶æ•°é‡ä¸åŒ¹é…ï¼Œè¯·é‡æ–°é€‰æ‹©æ–‡ä»¶ï¼")
                self.finished.emit()
            
            for idx, (input_file, input_srt) in enumerate(zip(video_files, srt_files)):
                if not os.path.exists(input_file):
                    self.status.emit(f"[ERROR] {input_file}æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·é‡æ–°é€‰æ‹©æ–‡ä»¶ï¼")
                    self.finished.emit()

                if not os.path.exists(input_srt):
                    self.status.emit(f"[ERROR] {input_srt}æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·é‡æ–°é€‰æ‹©æ–‡ä»¶ï¼")
                    self.finished.emit()

                input_srt = shutil.copy(input_srt, 'project/cache/')

                self.status.emit(f"[INFO] å½“å‰å¤„ç†æ–‡ä»¶ï¼š{input_file} ç¬¬{idx+1}ä¸ªï¼Œå…±{len(video_files)}ä¸ª")
                self.pid = subprocess.Popen(['ffmpeg', '-y', '-i', input_file,  '-vf', f'subtitles={input_srt}', '-vcodec', 'libx264', '-acodec', 'aac', input_file+'_synth.mp4'], stdout=sys.stdout, stderr=sys.stdout, creationflags=0x08000000)
                self.pid.wait()
                self.pid.kill()
                self.pid.terminate()
                self.status.emit("[INFO] è§†é¢‘åˆæˆå®Œæˆï¼")
            
        self.finished.emit()

    @error_handler
    def clip(self):
        self.save_config()
        input_files = self.master.clip_files_list.toPlainText()
        clip_start = self.master.clip_start_time.text()
        clip_end = self.master.clip_end_time.text()
        if input_files:
            input_files = input_files.strip().split('\n')
            for idx, input_file in enumerate(input_files):
                if not os.path.exists(input_file):
                    self.status.emit(f"[ERROR] {input_file}æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·é‡æ–°é€‰æ‹©æ–‡ä»¶ï¼")
                    self.finished.emit()

                self.status.emit(f"[INFO] å½“å‰å¤„ç†æ–‡ä»¶ï¼š{input_file} ç¬¬{idx+1}ä¸ªï¼Œå…±{len(input_files)}ä¸ª")
                self.status.emit(f"[INFO] æ­£åœ¨è¿›è¡Œåˆ‡ç‰‡...ä»{clip_start}åˆ°{clip_end}...")
                self.pid = subprocess.Popen(['ffmpeg', '-y', '-i', input_file, '-ss', clip_start, '-to', clip_end, '-vcodec', 'libx264', '-acodec', 'aac', os.path.join(*(input_file.split('.')[:-1]))+'_clip.'+input_file.split('.')[-1]], stdout=sys.stdout, stderr=sys.stdout, creationflags=0x08000000)
                self.pid.wait()
                self.pid.kill()
                self.pid.terminate()
                self.status.emit("[INFO] è§†é¢‘åˆ‡ç‰‡å®Œæˆï¼")
        self.finished.emit()

    @error_handler
    def audiosynth(self):
        self.save_config()
        input_files = self.master.synth_audio_files_list.toPlainText()
        if input_files:
            input_files = input_files.strip().split('\n')
            audio_files = sorted([i for i in input_files if i.endswith('.wav') or i.endswith('.mp3') or i.endswith('.flac')])
            image_files = sorted([i for i in input_files if i.endswith('.png') or i.endswith('.jpg') or i.endswith('.jpeg')])
            if len(audio_files) != len(image_files):
                self.status.emit("[ERROR] éŸ³é¢‘æ–‡ä»¶å’Œå›¾åƒæ–‡ä»¶æ•°é‡ä¸åŒ¹é…ï¼Œè¯·é‡æ–°é€‰æ‹©æ–‡ä»¶ï¼")
                self.finished.emit()
            
            for idx, (audio_input, image_input) in enumerate(zip(audio_files, image_files)):
                if not os.path.exists(audio_input):
                    self.status.emit(f"[ERROR] {audio_input}æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·é‡æ–°é€‰æ‹©æ–‡ä»¶ï¼")
                    self.finished.emit()

                if not os.path.exists(image_input):
                    self.status.emit(f"[ERROR] {image_input}æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·é‡æ–°é€‰æ‹©æ–‡ä»¶ï¼")
                    self.finished.emit()

                self.status.emit(f"[INFO] å½“å‰å¤„ç†æ–‡ä»¶ï¼š{audio_input} ç¬¬{idx+1}ä¸ªï¼Œå…±{len(image_files)}ä¸ª")
                self.pid = subprocess.Popen(['ffmpeg', '-y', '-loop', '1', '-r', '1', '-f', 'image2', '-i', image_input, '-i', audio_input, '-shortest', '-vcodec', 'libx264', '-acodec', 'aac', audio_input+'_synth.mp4'], stdout=sys.stdout, stderr=sys.stdout, creationflags=0x08000000)
                self.pid.wait()
                self.pid.kill()
                self.pid.terminate()
                self.status.emit("[INFO] è§†é¢‘åˆæˆå®Œæˆï¼")
            
        self.finished.emit()

    @error_handler
    def run(self):
        self.save_config()
        input_files = self.master.input_files_list.toPlainText()
        yt_url = self.master.yt_url.toPlainText()
        whisper_file = self.master.whisper_file.currentText()
        translator = self.master.translator_group.currentText()
        language = self.master.input_lang.currentText()
        gpt_token = self.master.gpt_token.text()
        gpt_address = self.master.gpt_address.text()
        gpt_model = self.master.gpt_model.text()
        sakura_file = self.master.sakura_file.currentText()
        sakura_mode = self.master.sakura_mode.value()
        proxy_address = self.master.proxy_address.text()
        before_dict = self.master.before_dict.toPlainText()
        gpt_dict = self.master.gpt_dict.toPlainText()
        after_dict = self.master.after_dict.toPlainText()
        extra_prompt = self.master.extra_prompt.toPlainText()
        param_whisper = self.master.param_whisper.toPlainText()
        param_whisper_faster = self.master.param_whisper_faster.toPlainText()
        param_llama = self.master.param_llama.toPlainText()
        output_format = self.master.output_format.currentText()

        if not gpt_token:
            gpt_token = 'sk-XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'

        with open('whisper/param.txt', 'w', encoding='utf-8') as f:
            f.write(param_whisper)

        with open('whisper-faster/param.txt', 'w', encoding='utf-8') as f:
            f.write(param_whisper_faster)

        with open('llama/param.txt', 'w', encoding='utf-8') as f:
            f.write(param_llama)

        self.status.emit("[INFO] æ­£åœ¨åˆå§‹åŒ–é¡¹ç›®æ–‡ä»¶å¤¹...")

        os.makedirs('project/cache', exist_ok=True)
        if before_dict:
            with open('project/dict_pre.txt', 'w', encoding='utf-8') as f:
                f.write(before_dict.replace(' ','\t'))
        else:
            if os.path.exists('project/dict_pre.txt'):
                os.remove('project/dict_pre.txt')
        if gpt_dict:
            with open('project/dict_gpt.txt', 'w', encoding='utf-8') as f:
                f.write(gpt_dict.replace(' ','\t'))
        else:
            if os.path.exists('project/dict_gpt.txt'):
                os.remove('project/dict_gpt.txt')
        if after_dict:
            with open('project/dict_after.txt', 'w', encoding='utf-8') as f:
                f.write(after_dict.replace(' ','\t'))
        else:
            if os.path.exists('project/dict_after.txt'):
                os.remove('project/dict_after.txt')
        if extra_prompt:
            with open('project/extra_prompt.txt', 'w', encoding='utf-8') as f:
                f.write(extra_prompt)
        else:
            if os.path.exists('project/extra_prompt.txt'):
                os.remove('project/extra_prompt.txt')

        self.status.emit(f"[INFO] å½“å‰è¾“å…¥æ–‡ä»¶ï¼š{input_files}, å½“å‰è§†é¢‘é“¾æ¥ï¼š{yt_url}")

        if input_files:
            input_files = input_files.split('\n')
        else:
            input_files = []

        if yt_url:
            input_files.extend(yt_url.split('\n'))

        os.makedirs('project/cache', exist_ok=True)

        self.status.emit("[INFO] æ­£åœ¨è¿›è¡Œç¿»è¯‘é…ç½®...")
        with open('project/config.yaml', 'r', encoding='utf-8') as f:
            lines = f.readlines()

        for idx, line in enumerate(lines):
            if 'language' in line:
                lines[idx] = f'  language: "{language}2zh-cn"\n'
            if 'gpt' in translator:
                if not gpt_address:
                    gpt_address = 'https://api.openai.com'
                if not gpt_model:
                    gpt_model = ''
                if 'GPT35:' in line:
                    lines[idx+2] = f"      - token: {gpt_token}\n"
                    lines[idx+4] = f"    defaultEndpoint: {gpt_address}\n"
                    lines[idx+5] = f'    rewriteModelName: "{gpt_model}"\n'
            for name, api in ONLINE_TRANSLATOR_MAPPING.items():
                if name == translator:
                    if 'llamacpp' in translator:
                        gpt_model = sakura_file
                    if 'GPT35:' in line:
                        lines[idx+2] = f"      - token: {gpt_token}\n"
                        lines[idx+4] = f"    defaultEndpoint: {api}\n"
                        lines[idx+5] = f'    rewriteModelName: "{gpt_model}"\n'
            if proxy_address:
                if 'proxy' in line:
                    lines[idx+1] = f"  enableProxy: true\n"
                    lines[idx+3] = f"    - address: {proxy_address}\n"
            else:
                if 'proxy' in line:
                    lines[idx+1] = f"  enableProxy: false\n"

        with open('project/config.yaml', 'w', encoding='utf-8') as f:
            f.writelines(lines)

        for idx, input_file in enumerate(input_files):
            if not os.path.exists(input_file):
                if input_file.startswith('BV'):
                    self.status.emit("[INFO] æ­£åœ¨ä¸‹è½½è§†é¢‘...")
                    res = send_request(URL_VIDEO_INFO, params={'bvid': input_file})
                    download([Video(
                        bvid=res['bvid'],
                        cid=res['cid'] if res['videos'] == 1 else res['pages'][0]['cid'],
                        title=res['title'] if res['videos'] == 1 else res['pages'][0]['part'],
                        up_name=res['owner']['name'],
                        cover_url=res['pic'] if res['videos'] == 1 else res['pages'][0]['pic'],
                    )], False)
                    self.status.emit("[INFO] è§†é¢‘ä¸‹è½½å®Œæˆï¼")
                    title = res['title'] if res['videos'] == 1 else res['pages'][0]['part']
                    title = re.sub(r'[.:?/\\]', ' ', title).strip()
                    title = re.sub(r'\s+', ' ', title)
                    input_file = f'{title}.mp4'

                else:
                    if os.path.exists('YoutubeDL.webm'):
                        os.remove('YoutubeDL.webm')
                    with YoutubeDL({'proxy': proxy_address,'outtmpl': 'YoutubeDL.webm'}) as ydl:
                        self.status.emit("[INFO] æ­£åœ¨ä¸‹è½½è§†é¢‘...")
                        results = ydl.download([input_file])
                        self.status.emit("[INFO] è§†é¢‘ä¸‹è½½å®Œæˆï¼")
                    input_file = 'YoutubeDL.webm'

                if os.path.exists(os.path.join('project/cache', os.path.basename(input_file))):
                    os.remove(os.path.join('project/cache', os.path.basename(input_file)))
                input_file = shutil.move(input_file, 'project/cache/')

            self.status.emit(f"[INFO] å½“å‰å¤„ç†æ–‡ä»¶ï¼š{input_file} ç¬¬{idx+1}ä¸ªï¼Œå…±{len(input_files)}ä¸ª")

            os.makedirs('project/gt_input', exist_ok=True)
            if input_file.endswith('.srt'):
                self.status.emit("[INFO] æ­£åœ¨è¿›è¡Œå­—å¹•è½¬æ¢...")
                output_file_path = os.path.join('project/gt_input', os.path.basename(input_file).replace('.srt','.json'))
                make_prompt(input_file, output_file_path)
                self.status.emit("[INFO] å­—å¹•è½¬æ¢å®Œæˆï¼")
                input_file = input_file[:-4]
            else:
                if whisper_file == 'ä¸è¿›è¡Œå¬å†™':
                    self.status.emit("[INFO] ä¸è¿›è¡Œå¬å†™ï¼Œè·³è¿‡å¬å†™æ­¥éª¤...")
                    continue

                wav_file = '.'.join(input_file.split('.')[:-1]) + '.16k.wav'
                self.status.emit("[INFO] æ­£åœ¨è¿›è¡ŒéŸ³é¢‘æå–...")
                self.pid = subprocess.Popen(['ffmpeg', '-y', '-i', input_file, '-acodec', 'pcm_s16le', '-ac', '1', '-ar', '16000', wav_file], stdout=sys.stdout, stderr=sys.stdout, creationflags=0x08000000)
                self.pid.wait()
                self.pid.kill()
                self.pid.terminate()

                if not os.path.exists(wav_file):
                    self.status.emit("[ERROR] éŸ³é¢‘æå–å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼ï¼")
                    break

                self.status.emit("[INFO] æ­£åœ¨è¿›è¡Œè¯­éŸ³è¯†åˆ«...")

                if whisper_file.startswith('ggml'):
                    print(param_whisper)
                    self.pid = subprocess.Popen([param.replace('$whisper_file',whisper_file).replace('$input_file',wav_file[:-4]).replace('$language',language) for param in param_whisper.split()], stdout=sys.stdout, stderr=sys.stdout, creationflags=0x08000000)
                elif whisper_file.startswith('faster-whisper'):
                    print(param_whisper_faster)
                    self.pid = subprocess.Popen([param.replace('$whisper_file',whisper_file[15:]).replace('$input_file',wav_file[:-4]).replace('$language',language).replace('$output_dir',os.path.dirname(input_file)) for param in param_whisper_faster.split()], stdout=sys.stdout, stderr=sys.stdout, creationflags=0x08000000)
                else:
                    self.status.emit("[INFO] ä¸è¿›è¡Œå¬å†™ï¼Œè·³è¿‡å¬å†™æ­¥éª¤...")
                    continue
                self.pid.wait()
                self.pid.kill()
                self.pid.terminate()

                input_file = wav_file[:-8]
                output_file_path = os.path.join('project/gt_input', os.path.basename(input_file)+'.json')
                make_prompt(wav_file[:-4]+'.srt', output_file_path)

                if output_format == 'åŸæ–‡SRT' or output_format == 'åŒè¯­SRT':
                    make_srt(output_file_path, input_file+'.srt')

                if os.path.exists(wav_file):
                    os.remove(wav_file)

                if os.path.exists(wav_file[:-4]+'.srt'):
                    os.remove(wav_file[:-4]+'.srt')
                self.status.emit("[INFO] è¯­éŸ³è¯†åˆ«å®Œæˆï¼")

            if translator == 'ä¸è¿›è¡Œç¿»è¯‘':
                self.status.emit("[INFO] ç¿»è¯‘å™¨æœªé€‰æ‹©ï¼Œè·³è¿‡ç¿»è¯‘æ­¥éª¤...")
                continue

            if language == 'zh':
                self.status.emit("[INFO] å¬å†™è¯­è¨€ä¸ºä¸­æ–‡ï¼Œè·³è¿‡ç¿»è¯‘æ­¥éª¤...")
                continue

            if 'sakura' in translator or 'llamacpp' in translator or 'galtransl' in translator:
                self.status.emit("[INFO] æ­£åœ¨å¯åŠ¨Llamacppç¿»è¯‘å™¨...")
                if not sakura_file:
                    self.status.emit("[INFO] æœªé€‰æ‹©æ¨¡å‹æ–‡ä»¶ï¼Œè·³è¿‡ç¿»è¯‘æ­¥éª¤...")
                    continue
                
                print(param_llama)
                self.pid = subprocess.Popen([param.replace('$model_file',sakura_file).replace('$num_layers',str(sakura_mode)).replace('$port', '8989') for param in param_llama.split()], stdout=sys.stdout, stderr=sys.stdout, creationflags=0x08000000)
                
                self.status.emit("[INFO] æ­£åœ¨ç­‰å¾…Sakuraç¿»è¯‘å™¨å¯åŠ¨...")
                while True:
                    try:
                        response = requests.get("http://localhost:8989")
                        if response.status_code == 200:
                            break
                    except requests.exceptions.RequestException:
                        pass
                    sleep(1)

            if 'galtransl' in translator:
                worker_trans = 'sakura-010'
            elif 'sakura' not in translator:
                worker_trans = 'gpt35-1106'
            else:
                worker_trans = translator

            self.status.emit("[INFO] æ­£åœ¨è¿›è¡Œç¿»è¯‘...")
            worker('project', 'config.yaml', worker_trans, show_banner=False)

            self.status.emit("[INFO] æ­£åœ¨ç”Ÿæˆå­—å¹•æ–‡ä»¶...")
            if output_format == 'ä¸­æ–‡SRT' or output_format == 'åŒè¯­SRT':
                make_srt(output_file_path.replace('gt_input','gt_output'), input_file+'.zh.srt')

            if output_format == 'ä¸­æ–‡LRC':
                make_lrc(output_file_path.replace('gt_input','gt_output'), input_file+'.lrc')

            if output_format == 'åŒè¯­SRT':
                merge_srt_files([input_file+'.srt',input_file+'.zh.srt'], input_file+'.combine.srt')

            self.status.emit("[INFO] å­—å¹•æ–‡ä»¶ç”Ÿæˆå®Œæˆï¼")

            if 'sakura' in translator or 'llamacpp' in translator or 'galtransl' in translator:
                self.status.emit("[INFO] æ­£åœ¨å…³é—­Llamacppç¿»è¯‘å™¨...")
                self.pid.kill()
                self.pid.terminate()

        self.status.emit("[INFO] æ‰€æœ‰æ–‡ä»¶å¤„ç†å®Œæˆï¼")
        self.finished.emit()

if __name__ == "__main__":
    QtCore.QCoreApplication.setAttribute(QtCore.Qt.AA_EnableHighDpiScaling)
    app = QApplication(sys.argv)
    main_window = MainWindow()
    main_window.show()
    sys.exit(app.exec_())
